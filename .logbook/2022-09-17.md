Fixed the bug in vm_map_iter mentioned yesterday. It was pretty trivial (just pass along the parent VFN; the offset.)

Most of the morning was spent on `vm_map_del`, the function used to remove, or "unmap" a range of virtual addresses. Using the new iterator API, I was able to write a pretty small and relatively elegant implementation.

However in doing so I discovered what I thought was a bug in rmm, the memory manager (host page allocator.) I spent the rest of the day on this, until 18:30! Ended up realizing I simply had a logic issue in vm_map: when freeing a mapping that had backing pages assigned, it would (incorrectly) be freed back to the rmm. This works for single backing pages allocated on demand, but breaks the expectations of `rmm_freepages` when a vm_map mapping was made with explicit backing host pages, in fact, with _more than one_ explicit backing host page.

The fix was to introduce a "purgeable" flag for vm_map PTEs, a flag set for pages which have backing pages assigned on demand. The flag is not set when mapping with a explicit backing host pages, as the caller of such a mapping is expected to manage those backing host pages.

To prevent this from happening again I added a `npages` argument to `rmm_freepages` and logic to detect "over free" and "under free"; attempts to free a block of pages that is larger or smaller than the actual block.
